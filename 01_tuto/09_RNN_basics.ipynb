{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### RNN Block Basics\n",
    "##### (ref. https://github.com/buomsoo-kim/PyTorch-learners-tutorial)\n",
    "##### (ref. https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of RNN\n",
    "\n",
    "\n",
    "Like human start their thinnking not from scratch but based on previous experience or memory  \n",
    "Neural Network could imitate to use previous data with Recurrent Neural Network(RNN)  \n",
    "Passing a message to successor node  \n",
    "It is successful to deal with sequence data  \n",
    "<br>\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*xLcQd_xeBWHeC6CeYSJ9bA.png)\n",
    "<br>\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*XosBFfduA1cZB340SSL1hg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Vanilla RNN\n",
    "\n",
    "![alt_text](https://cdn-images-1.medium.com/max/1600/1*ccHxugJhQo7VH4GAAZt3Sg.png)\n",
    "<br>\n",
    "![alt_text](https://cdn-images-1.medium.com/max/1200/1*jLWB_Dute-qB43DXqe8G3Q.png)\n",
    "\n",
    "- ```torch.nn.RNN()```: multi-layer Elman RNN\n",
    "  - Parameters\n",
    "      - ```input_size``` : The number of expected features in the input `x` (the number of activation block)\n",
    "      - ```hidden_size``` : The number of features in the hidden state `h` (the number of nodes in block)\n",
    "      - ```num_layers``` : Number of recurrent layers. if 2 then stacked RNN with 2 layers (stacked RMN layers aboved RNN layer)\n",
    "      - ```nonlinearity``` : activation function with tanh or relu\n",
    "      - ```batch_first``` :  If True, then the input and output tensors are provided as `(batch, seq, feature)\n",
    "      - ```bidirectional``` :  If True, bidirectional RNN\n",
    "   \n",
    "stacked RNN\n",
    "![alt_text](https://lh6.googleusercontent.com/rC1DSgjlmobtRxMPFi14hkMdDqSkEkuOX7EW_QrLFSymjasIM95Za2Wf-VwSC1Tq1sjJlOPLJ92q7PTKJh2hjBoXQawM6MQC27east67GFDklTalljlt0cFLZnPMdhp8erzO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 10, \n",
    "             num_layers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 10]) torch.Size([1, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "## inputs to RNN\n",
    "# input data (seq_len, batch_size, input_size)\n",
    "x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n",
    "# hidden state (num_layers * num_directions, batch_size, hidden_size)\n",
    "h0 = torch.from_numpy(np.zeros((1, 64, 10))).float()            \n",
    "\n",
    "print(x0.shape, h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 10]) torch.Size([1, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "out, h1 = rnn(x0, h0) # the input size of x0 and h0 should be same as the input_size paramter of nn.RNN\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when batch_first = True\n",
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 2,     # stacked RNN (2 layers)\n",
    "             batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 10]) torch.Size([2, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## inputs to RNN\n",
    "x0 = torch.from_numpy(np.random.randn(64, 12, 10)).float()     \n",
    "# note that even batch_first == True, hidden state shape order does not change\n",
    "h0 = torch.from_numpy(np.zeros((2, 64, 5))).float() # As the number of RNN Layer is 2, h0 should have 2 values\n",
    "\n",
    "print(x0.shape, h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 5]) torch.Size([2, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "out, h1 = rnn(x0, h0) # the input size of x0 and h0 should be same as the input_size paramter of nn.RNN\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 10]) torch.Size([8, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "# bidirectional, stacked RNN\n",
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 4,     \n",
    "             bidirectional = True)\n",
    "\n",
    "x0 = torch.from_numpy(np.random.randn(5, 64, 10)).float()\n",
    "h0 = torch.from_numpy(np.zeros((4 * 2, 64, 5))).float()  # notice the dimensionality of hidden state\n",
    "out, h1 = rnn(x0, h0)\n",
    "\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Notions for convolution layer\n",
    "    - **Kernel Size** – the size of the filter.\n",
    "    - **Kernel Type** – the values of the actual filter. Some examples include identity, edge detection, and sharpen\n",
    "    - **Stride** – the rate at which the kernel passes over the input image. A stride of 2 moves the kernel in 2-pixel increments\n",
    "    - **Padding** – we can add layers of 0s to the outside of the image in order to make sure that the kernel properly passes over the edges of the image\n",
    "    - **Output Layers** – how many different kernels are applied to the image\n",
    "\n",
    "\n",
    "- How to calculate output size of convolution operation\n",
    "  <br> \n",
    "*(W - F + 2P)/S + 1* <br>\n",
    "  - *W*: input size\n",
    "  - *F*: kernel size\n",
    "  - *P*: padding \n",
    "  - *S*: stride\n",
    "  \n",
    "![alt text](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\n",
    "<br>\n",
    "<br>\n",
    "![alt_text](https://qph.fs.quoracdn.net/main-qimg-af9899617c2beedbc89c036e3b8a9e78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
