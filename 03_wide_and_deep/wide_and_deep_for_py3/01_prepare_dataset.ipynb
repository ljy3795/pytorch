{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prepare the data set for Wide and Deep Learning\n",
    "(Ref. : https://github.com/jrzaurin/Wide-and-Deep-PyTorch)\n",
    "- These are the steps to prepare the data set for \"Wide and Deep Learning\" model at `wide_deep/torch_model.py`\n",
    "- Steps:\n",
    "  - 1) Load data set\n",
    "  - 2) Target Labeling & Column Labeling for the Wide and for the Deep\n",
    "  - 3) Prepare the features for the Wide `wide_cols & crossed_cols` and Deep `embedding_cols, continuous_cols`\n",
    "  - 4) Split the data set to Train & Test and output as dict type\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T06:45:38.897759Z",
     "start_time": "2018-09-04T06:45:38.893901Z"
    }
   },
   "source": [
    "#### 1) Load Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T06:47:29.460177Z",
     "start_time": "2018-09-04T06:47:29.361350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 16)\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'income_bracket', 'income_label'],\n",
      "      dtype='object')\n",
      "   age         workclass  fnlwgt  education  education_num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital_status         occupation   relationship   race  gender  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \\\n",
      "0          2174             0              40  United-States          <=50K   \n",
      "1             0             0              13  United-States          <=50K   \n",
      "2             0             0              40  United-States          <=50K   \n",
      "3             0             0              40  United-States          <=50K   \n",
      "4             0             0              40           Cuba          <=50K   \n",
      "\n",
      "   income_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time\n",
    "\n",
    "### Load the data set from '.data/audult_data.csv'\n",
    "raw_df = pd.read_csv(os.path.join(str(os.getcwd()), 'data/adult_data.csv'))\n",
    "print(raw_df.shape)\n",
    "print(raw_df.columns)\n",
    "print(raw_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Target Labeling & Column Labeling for the Wide and for the Deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Label the Targets for binary classification\n",
    " - Label the targets for binary classification \n",
    " - We set the target with income bracket over 50K (>50K) as `income_label`\n",
    "   - 1 if >50K else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T07:47:04.874038Z",
     "start_time": "2018-09-04T07:47:04.828105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K' '<=50K.' '>50K.']\n",
      "Target : 11687 / Non-Target : 37155\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "gender            object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income_bracket    object\n",
      "income_label       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \\\n",
       "0          2174             0              40  United-States          <=50K   \n",
       "1             0             0              13  United-States          <=50K   \n",
       "2             0             0              40  United-States          <=50K   \n",
       "3             0             0              40  United-States          <=50K   \n",
       "4             0             0              40           Cuba          <=50K   \n",
       "\n",
       "   income_label  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_df['income_bracket'].unique())\n",
    "\n",
    "raw_df['income_label'] = raw_df['income_bracket'].apply(lambda x: 1 if '>50K' in x or '>50K.' in x else 0)\n",
    "print('Target : {} / Non-Target : {}'.format(len(raw_df[raw_df.income_label == 1]), len(raw_df[raw_df.income_label != 1])))\n",
    "print(raw_df.dtypes)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T07:50:49.147726Z",
     "start_time": "2018-09-04T07:50:49.143724Z"
    }
   },
   "source": [
    "Step 2. Set the columns for the Wide part & the Deep part and handling of each featues\n",
    " - For the Wide part, we are going to use the columns for memorization by `Linear Layer`\n",
    " - For the Deep part, we are going to use the columns for generalization by `Embedding Layer and Linear Layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:30:17.665411Z",
     "start_time": "2018-09-04T08:30:17.659384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'hours_per_week', 'education', 'relationship', 'workclass', 'occupation', 'native_country', 'gender']\n",
      "['education', 'relationship', 'workclass', 'occupation', 'native_country', 'age', 'hours_per_week']\n"
     ]
    }
   ],
   "source": [
    "# For Wide and Crossed network (for memorization)\n",
    "wide_cols = ['age','hours_per_week','education', 'relationship','workclass',\n",
    "             'occupation','native_country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native_country', 'occupation']) # pair-combination \n",
    "\n",
    "# For Deep network (embedding + continuous) (for generalization)\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "\n",
    "embeddings_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                    ('occupation',10),('native_country',12)] # column name / embedding dim.\n",
    "\n",
    "embdding_dim = dict(embeddings_cols)\n",
    "embeddings_cols = list(embdding_dim.keys())\n",
    "\n",
    "deep_cols = embeddings_cols + continuous_cols\n",
    "\n",
    "print(wide_cols)\n",
    "print(deep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:30:19.685553Z",
     "start_time": "2018-09-04T08:30:17.904542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Bachelors-Adm-clerical\n",
      "1    Bachelors-Exec-managerial\n",
      "2    HS-grad-Handlers-cleaners\n",
      "3       11th-Handlers-cleaners\n",
      "4     Bachelors-Prof-specialty\n",
      "Name: education-occupation, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target variable\n",
    "target_Y = np.array(raw_df['income_label'])\n",
    "\n",
    "# feature handling for wide and deep columns\n",
    "tmp_df = raw_df.copy()[list(set(wide_cols + deep_cols))]\n",
    "\n",
    "# Make crossed cols\n",
    "crossed_columns = []\n",
    "for cols in crossed_cols:\n",
    "    tmp_col_nm = '-'.join(cols)\n",
    "    tmp_df[tmp_col_nm] = tmp_df[cols].apply(lambda x: '-'.join(x), axis = 1)\n",
    "    crossed_columns.append(tmp_col_nm)\n",
    "\n",
    "print(tmp_df[crossed_columns[0]].head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding of categorical columns, do following 3 steps\n",
    " - find unique values for each column\n",
    " - set index(encoding values) for each unique values\n",
    " - convert categorical values to corresponding encoding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:30:19.865853Z",
     "start_time": "2018-09-04T08:30:19.687625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['native_country', 'workclass', 'occupation', 'education', 'relationship', 'gender', 'education-occupation', 'native_country-occupation']\n",
      "[['native_country', 42, 12], ['workclass', 9, 10], ['occupation', 15, 10], ['education', 16, 10], ['relationship', 6, 8]]\n"
     ]
    }
   ],
   "source": [
    "## encoding for categorical columns\n",
    "\n",
    "# find categorical variables\n",
    "categorical_cols = list(tmp_df.select_dtypes(include = 'object').columns)\n",
    "print(categorical_cols)\n",
    "\n",
    "\n",
    "# step 1:\n",
    "unique_values = dict()\n",
    "for col in categorical_cols:\n",
    "    unique_values[col] = list(tmp_df[col].unique())\n",
    "    \n",
    "# step 2:\n",
    "val_2_inx = dict()\n",
    "for k, v in unique_values.items():\n",
    "    val_2_inx[k] = {v2: i for i, v2 in enumerate(unique_values[k])}\n",
    "    \n",
    "# step 3:\n",
    "for k, v in val_2_inx.items():\n",
    "    tmp_df[k] = tmp_df[k].apply(lambda x: val_2_inx[k][x])\n",
    "    \n",
    "\n",
    "# only for deep cols, make embedding cols info\n",
    "encoding_dict = {k: v for k, v in val_2_inx.items() if k in deep_cols}\n",
    "embeddings_input = []\n",
    "for k, v in encoding_dict.items():\n",
    "    embeddings_input.append([k, len(v), embdding_dim[k]]) # column name, number of unique items, embedding dims\n",
    "print(embeddings_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling for continuous(numerical) data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:32:49.649462Z",
     "start_time": "2018-09-04T08:32:49.643068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.287798580766198e-17 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "for col in continuous_cols:\n",
    "    tmp_df[col] = scaler.fit_transform(tmp_df[col].values.reshape(-1,1))\n",
    "print(np.mean(tmp_df[col].values), np.std(tmp_df[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Prepare the features for the Wide wide_cols & crossed_cols and Deep embedding_cols, continuous_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:40:00.890186Z",
     "start_time": "2018-09-04T08:40:00.886376Z"
    }
   },
   "source": [
    "Step 1. split the df to the Wide part and the Deep part dataframe\n",
    " - For categorical variables in the Wide part, use one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:46:54.630351Z",
     "start_time": "2018-09-04T08:46:54.488601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 7)\n",
      "(48842, 10)\n",
      "(48842, 798)\n"
     ]
    }
   ],
   "source": [
    "df_deep = tmp_df[deep_cols]\n",
    "deep_column_idx = {k:v for v,k in enumerate(df_deep.columns)}\n",
    "print(df_deep.shape)\n",
    "\n",
    "# for categorical variables in the Wide part, we are not going to use encoing variable instead one-hot encoding variables\n",
    "df_wide = tmp_df[wide_cols + crossed_columns]\n",
    "print(df_wide.shape)\n",
    "one_hot_cols = [c for c in wide_cols+crossed_columns if c in categorical_cols]\n",
    "df_wide = pd.get_dummies(df_wide, columns=one_hot_cols)\n",
    "print(df_wide.shape) # by converting categorical variables to one-hot dummys, columns length increased from 10 to 798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:41:02.343940Z",
     "start_time": "2018-09-04T08:41:02.341154Z"
    }
   },
   "source": [
    "#### 4) Split the data set to Train & Test and output as dict type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:47:23.723645Z",
     "start_time": "2018-09-04T08:47:23.125681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 7)\n",
      "(34189, 798)\n",
      "(34189,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "\n",
    "seed = 1\n",
    "x_train_deep, x_test_deep = train_test_split(df_deep.values, test_size = 0.3, random_state = seed)\n",
    "x_train_wide, x_test_wide = train_test_split(df_wide.values, test_size = 0.3, random_state = seed)\n",
    "y_train, y_test = train_test_split(target_Y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "print(x_train_deep.shape)\n",
    "print(x_train_wide.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "# make the output dictionary\n",
    "out_dataset = dict()\n",
    "train_set = namedtuple('train_set', 'wide, deep, labels')\n",
    "test_set = namedtuple('test_set', 'wide, deep, labels')\n",
    "out_dataset['train_set'] = train_set(x_train_wide, x_train_deep, y_train)\n",
    "out_dataset['test_set'] = test_set(x_test_wide, x_test_deep, y_test)\n",
    "out_dataset['embeddings_input'] = embeddings_input\n",
    "out_dataset['deep_column_idx'] = deep_column_idx\n",
    "out_dataset['encoding_dict'] = encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T08:47:28.867225Z",
     "start_time": "2018-09-04T08:47:28.861441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_set(wide=array([[-0.99512893, -0.35689365,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.17187097,  1.57994645,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.02599598, -0.03408696,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.48456647,  0.36942139,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.84925394, -0.03408696,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.99512893, -0.03408696,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]]), deep=array([[ 1.        ,  3.        ,  2.        , ...,  0.        ,\n",
       "        -0.99512893, -0.35689365],\n",
       "       [ 1.        ,  1.        ,  2.        , ...,  0.        ,\n",
       "         0.17187097,  1.57994645],\n",
       "       [ 6.        ,  4.        ,  2.        , ...,  0.        ,\n",
       "         0.02599598, -0.03408696],\n",
       "       ...,\n",
       "       [ 0.        ,  1.        ,  2.        , ...,  0.        ,\n",
       "        -0.48456647,  0.36942139],\n",
       "       [ 0.        ,  0.        ,  2.        , ...,  4.        ,\n",
       "        -0.84925394, -0.03408696],\n",
       "       [ 0.        ,  3.        ,  2.        , ...,  0.        ,\n",
       "        -0.99512893, -0.03408696]]), labels=array([0, 1, 0, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dataset['train_set']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
